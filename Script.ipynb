{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4df7b5b-d965-46f9-a3d1-3a2b1495d1bf",
   "metadata": {},
   "source": [
    "# Procedures script to read the raw building list from a Telecommunication service provider and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a935e68c-e512-43a6-8f03-32371df38061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95e3c0-a1a0-4204-9af1-493f6b6fd03c",
   "metadata": {},
   "source": [
    "1- Reading the buildings list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c251b5ac-eea5-4a08-b960-9b5f747fb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = pd.read_excel('Lit Building Inventory - Public.xlsx', skiprows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb10a71-6c2a-4d3e-a576-91ba0fb68535",
   "metadata": {},
   "source": [
    "2- Reformat the buildings list and prepare it for SmartyStreets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eccd4c5-41a0-4f74-a6b0-1368c38e702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformat_list = pd.DataFrame({'Street Address':list['Lit Building List'], 'City':list['City'], 'State':list['State'], 'Zip Code':list['Postal']})\n",
    "reformat_list.to_csv(f'SmartyStreets\\input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e9bb2c-4d97-409f-acce-7c2865cedfbb",
   "metadata": {},
   "source": [
    "3- Run SmartyStreets from its folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ed7fa-937a-4f8d-83dd-4746d45b09c2",
   "metadata": {},
   "source": [
    "4- Reading the result list of SmartyStreets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec4b6d0-e3d1-4265-9ebd-b8f83f80e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_list = pd.read_csv(f'SmartyStreets\\output.csv')\n",
    "sm_list = sm_list.fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d734ff-49d7-4f6d-bb4e-46bf010db49b",
   "metadata": {},
   "source": [
    "5- Preparing the new address formula to be ready for geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e686c6d1-9ac1-4522-ad41-a8653e273362",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_list['new address'] = sm_list.apply(lambda i: i['[primary_number]']+' '+i['[street_predirection]']+''+i['[street_name]']+' '+i['[street_suffix]']+' '+i['[street_postdirection]'], axis=1)\n",
    "sm_list['new city'] = sm_list['[default_city_name]']\n",
    "sm_list['new state'] = sm_list['[state_abbreviation]']\n",
    "sm_list['new zipcode'] = sm_list['[zipcode]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d624f1-4af9-4cba-a67e-7580eecdd5f5",
   "metadata": {},
   "source": [
    "6- Checking for bad addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89723528-adfc-402d-bdb6-94f808ae3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in sm_list.iterrows():\n",
    "    # Check if the address misssing the primary number\n",
    "    if row['new address'][0].isdigit() == False:\n",
    "        print(row['new address'])\n",
    "    # Check if street name is missing\n",
    "    if len(row['[street_name]']) == 0:\n",
    "        print(row['[street_name]'])\n",
    "    # Check if street name contains a 'PO box'\n",
    "    if 'PO box' in (row['[street_name]']):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5631d0-d6b3-4478-8488-45408f10053b",
   "metadata": {},
   "source": [
    "7- Filtering dublicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea0b526-c51e-47ba-8718-1965ae6e66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = sm_list.loc[sm_list.duplicated(subset=['new address', 'new state', 'new zipcode'])]\n",
    "dups.to_excel('duplicated.xlsx', columns=['new address', 'new state', 'new zipcode'])\n",
    "sm_list = sm_list.drop_duplicates(subset=['new address', 'new state', 'new zipcode'], keep='first')\n",
    "sm_list['ID'] = sm_list.index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468642cb-7381-4ec4-bc25-521a263e810b",
   "metadata": {},
   "source": [
    "8- Prepare the input list of geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4c5152-70ec-4c8f-a122-a90360c654d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_input = pd.DataFrame({'ID':sm_list.index+1,\n",
    "                         'Address':sm_list['new address'],\n",
    "                         'City':sm_list['new city'],\n",
    "                         'State':sm_list['new state'],\n",
    "                         'Country':'USA',\n",
    "                         'Postal':sm_list['new zipcode']})\n",
    "\n",
    "gc_input.to_csv(f'c2f_geocoder\\c2f_geocoder\\gc_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868f425-1588-4364-999c-4e39814516a9",
   "metadata": {},
   "source": [
    "9- Run the geocoding script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17baf6-5e6b-430c-8557-12d3e0188674",
   "metadata": {},
   "source": [
    "10- Reading the result list of geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3d77ef-36c3-461e-a5a2-27b1d1c422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_output = pd.read_csv(f'c2f_geocoder\\c2f_geocoder\\gc_output.csv')\n",
    "gc_output.rename(columns={'id':'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642256a-d67f-4109-9cb4-dd88ae450964",
   "metadata": {},
   "source": [
    "11- Filtering the good addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1fd60a-5e19-45b8-8942-7408ecdc070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_addresses = gc_output.loc[(gc_output['accuracy_type'] == 'house number') & (gc_output['accuracy'] >= 0.8)]\n",
    "good_addresses[['lat','long','Postal']].astype(str)\n",
    "good_addresses = good_addresses.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63c58a-81af-4278-be5f-4fd806090436",
   "metadata": {},
   "source": [
    "12- Check for bad addresses that we could take their Lat/Long values from SamrtStreets result list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fab72-a196-4f4e-9aa7-a51f0f1ba4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_adds_list = []\n",
    "for idx, row in gc_output.iterrows():\n",
    "    if (row['accuracy_type'] != 'house number') & (row['accuracy'] >= 0.8):\n",
    "        sm_adds = sm_list[sm_list['new address'] == row['address']]\n",
    "        sm_adds['accuracy'] = row['accuracy']\n",
    "        sm_adds['accuracy_type'] = row['accuracy_type']\n",
    "        sm_adds['country'] = 'USA'\n",
    "        sm_adds = sm_adds[['new address', 'new city', 'new state', 'country', '[latitude]', '[longitude]', 'accuracy', 'accuracy_type', 'new zipcode']]\n",
    "        columns_map = {'new address':'address', 'new city':'city', 'new state':'state', '[latitude]':'lat', '[longitude]':'long', 'new zipcode':'Postal'}\n",
    "        sm_adds.rename(columns=columns_map, inplace=True)\n",
    "        new_good = pd.concat([good_addresses, sm_adds], axis=0)\n",
    "        new_good.to_csv(f'c2f_geocoder\\c2f_geocoder\\good.csv')\n",
    "    # Check if there is bad addresses which its [accuracy] < 0.8 even if its [accuracy_type] == 'house number'\n",
    "    if (row['accuracy_type'] == 'house number') & (row['accuracy'] < 0.8):\n",
    "        bad_adds_list.append(row)\n",
    "        bad_adds = pd.DataFrame(bad_adds_list, columns=gc_output.columns)\n",
    "        bad_adds.to_csv(f'c2f_geocoder\\c2f_geocoder\\Bad.csv')\n",
    "        print('there are bad addresses, and it saved in a csv file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32500d6a-82af-4fb8-bda1-546378225f12",
   "metadata": {},
   "source": [
    "13- Export good addresses in a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ad5d55-4d07-45d4-9707-9b94b71cb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_addresses.to_csv(f'c2f_geocoder\\c2f_geocoder\\good.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e21cb1dc-7dd1-4c64-81f8-3bb4b85fb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clli = gpd.read_file(f'clli_boundary\\clli_boundary.shp')[['sw_clli', 'npa', 'nxx', 'lata', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47285bdb-ce6b-48c0-81e7-5d6ee1b1405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blg_list_geom = [Point(xy) for xy in zip(good_addresses['long'], good_addresses['lat'])]\n",
    "blg_list_gdf = gpd.GeoDataFrame(good_addresses, crs='EPSG:4326', geometry=blg_list_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e4bc7-7b06-40b7-af2c-5085e21d84ca",
   "metadata": {},
   "source": [
    "14- Implement a spatial join to add the needed data from columns ('sw_clli', 'npa', 'nxx', 'lata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5e22205-7a6c-4247-b2e4-432d9f90a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "join = gpd.sjoin(blg_list_gdf, clli, how='left', predicate='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e82e4d00-c7b7-4abe-821d-ad0ebdc986e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = join.drop_duplicates(subset='address', keep='first')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
